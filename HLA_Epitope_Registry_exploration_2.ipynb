{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche de motifs fréquents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "import re\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def import_data_from_HLA_Epitope_Registry(database) :\n",
    "    \"\"\"Gets the contents of one database of HLA Epitope Registry.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    database : str\n",
    "        The database name (\"ABC\", \"DRB\", \"DQ\"/\"DQB+DQA\", \"DP\"/\"DPB+DPA\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (entries, list_of_luminex_alleles, list_of_all_alleles) : (dict of str: [str, str, str, str, str], list of str, list of str)\n",
    "        entries[eplet] = [ellipro_score, polymorphic_residues, antibody_reactivity, luminex_alleles, all_alleles]\n",
    "        Comma-separated lists of alleles\n",
    "    \"\"\"\n",
    "\n",
    "    if database == \"DQB+DQA\" :\n",
    "        database = \"DQ\"\n",
    "    elif database == \"DPB+DPA\" :\n",
    "        database = \"DP\"\n",
    "\n",
    "    url = \"https://www.epregistry.com.br/index/databases/database/\"+database+\"/\"\n",
    "    page = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    entries = {}\n",
    "    list_of_luminex_alleles = []\n",
    "    list_of_all_alleles = []\n",
    "    for l in soup.find(id=\"table-result\").find(\"tbody\").find_all(\"tr\", recursive=False) :  # lignes du tableau\n",
    "        e = l.find_all(\"td\", recursive=False)   # les différentes 'cases'\n",
    "        eplet = e[0].text.strip()\n",
    "        suffix = \"\"\n",
    "        ellipro_score = e[1].text.strip()\n",
    "        if ellipro_score == \"High\" :\n",
    "            suffix += 'h'\n",
    "        polymorphic_residues = e[2].text.strip()\n",
    "        if e[4].text.strip() == '' :\n",
    "            antibody_reactivity = 0\n",
    "        else :\n",
    "            antibody_reactivity = 1\n",
    "            suffix += 'c'\n",
    "        luminex_alleles = e[6].find(\"div\", {\"class\":\"modal-body\"}).text.strip()\n",
    "        all_alleles = e[7].find(\"div\", {\"class\":\"modal-body\"}).text.strip()\n",
    "        if suffix != '' :\n",
    "            eplet += \"_\"+suffix\n",
    "        entries[eplet] = [ellipro_score, polymorphic_residues, antibody_reactivity, luminex_alleles, all_alleles]\n",
    "\n",
    "        for allele in luminex_alleles.split() :\n",
    "            allele = allele.replace(',', '')\n",
    "            if allele not in list_of_luminex_alleles :\n",
    "                list_of_luminex_alleles.append(allele)\n",
    "        for allele in all_alleles.split() :\n",
    "            allele = allele.replace(',', '')\n",
    "            if allele not in list_of_all_alleles :\n",
    "                list_of_all_alleles.append(allele)\n",
    "\n",
    "    return (entries, list_of_luminex_alleles, list_of_all_alleles)\n",
    "\n",
    "def create_matrices(entries, list_of_luminex_alleles, list_of_all_alleles) :\n",
    "    \"\"\"Creates 4 DataFrames from the output of import_data_from_HLA_Epitope_Registry().\n",
    "\n",
    "    Outputs the matrices created by the combinations of confirmed eplets / all eplets and Luminex alleles / all alleles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Output of import_data_from_HLA_Epitope_Registry()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (df_all_eplets_vs_Luminex_alleles, df_all_eplets_vs_all_alleles, df_confirmed_eplets_vs_Luminex_alleles, df_confirmed_eplets_vs_all_alleles) :\n",
    "        tuple of 4 pandas DataFrames\n",
    "        Binary matrices (filled with zeroes and ones). Eplets as rows, alleles as columns.\n",
    "    \"\"\"\n",
    "    sorted_list_of_luminex_alleles = sorted(list_of_luminex_alleles)\n",
    "    sorted_list_of_all_alleles = sorted(list_of_all_alleles)\n",
    "\n",
    "    eplets_list = []\n",
    "    confirmed_eplets_list = []\n",
    "\n",
    "    Luminex_alleles_vs_all_eplets = {}\n",
    "    Luminex_alleles_vs_confirmed_eplets = {}\n",
    "    all_alleles_vs_all_eplets = {}\n",
    "    all_alleles_vs_confirmed_eplets = {}\n",
    "\n",
    "    for eplet in entries :\n",
    "        Luminex_alleles_associated_with_eplet = [x.strip() for x in entries[eplet][3].split(',')]\n",
    "        all_alleles_associated_with_eplet = [x.strip() for x in entries[eplet][4].split(',')]\n",
    "\n",
    "        eplets_list.append(eplet)\n",
    "\n",
    "        d = []\n",
    "        for a in sorted_list_of_luminex_alleles :\n",
    "            if a in Luminex_alleles_associated_with_eplet :\n",
    "                d.append(1)\n",
    "            else :\n",
    "                d.append(0)\n",
    "        Luminex_alleles_vs_all_eplets[eplet] = d\n",
    "\n",
    "        d = []\n",
    "        for a in sorted_list_of_all_alleles :\n",
    "            if a in all_alleles_associated_with_eplet :\n",
    "                d.append(1)\n",
    "            else :\n",
    "                d.append(0)\n",
    "        all_alleles_vs_all_eplets[eplet] = d\n",
    "\n",
    "        if entries[eplet][2] : # if antibody reactivity\n",
    "            confirmed_eplets_list.append(eplet)\n",
    "\n",
    "            d = []\n",
    "            for a in sorted_list_of_luminex_alleles :\n",
    "                if a in Luminex_alleles_associated_with_eplet :\n",
    "                    d.append(1)\n",
    "                else :\n",
    "                    d.append(0)\n",
    "            Luminex_alleles_vs_confirmed_eplets[eplet] = d\n",
    "\n",
    "            d = []\n",
    "            for a in sorted_list_of_all_alleles :\n",
    "                if a in all_alleles_associated_with_eplet :\n",
    "                    d.append(1)\n",
    "                else :\n",
    "                    d.append(0)\n",
    "            all_alleles_vs_confirmed_eplets[eplet] = d\n",
    "\n",
    "\n",
    "    df_all_eplets_vs_Luminex_alleles = pd.DataFrame(Luminex_alleles_vs_all_eplets, index=sorted_list_of_luminex_alleles).transpose()\n",
    "    df_all_eplets_vs_all_alleles = pd.DataFrame(all_alleles_vs_all_eplets, index=sorted_list_of_all_alleles).transpose()\n",
    "    df_confirmed_eplets_vs_Luminex_alleles = pd.DataFrame(Luminex_alleles_vs_confirmed_eplets, index=sorted_list_of_luminex_alleles).transpose()\n",
    "    df_confirmed_eplets_vs_all_alleles = pd.DataFrame(all_alleles_vs_confirmed_eplets, index=sorted_list_of_all_alleles).transpose()\n",
    "\n",
    "    return (df_all_eplets_vs_Luminex_alleles, df_all_eplets_vs_all_alleles, df_confirmed_eplets_vs_Luminex_alleles, df_confirmed_eplets_vs_all_alleles)\n",
    "\n",
    "\n",
    "def split_A_B(df_eplets_vs_alleles) :\n",
    "    A = df_eplets_vs_alleles.filter(regex='A')\n",
    "    B = df_eplets_vs_alleles.filter(regex='B')\n",
    "    A = A[(A.T != 0).any()] # delete rows with only zeroes\n",
    "    B = B[(B.T != 0).any()]\n",
    "    return (A, B)\n",
    "\n",
    "\n",
    "def get_that_fucking_list(df) :\n",
    "    array = df.to_numpy()\n",
    "    l = []\n",
    "    list_of_items_names = df.columns.values \n",
    "    list_of_transactions_names = df.index.values\n",
    "    for e in array :\n",
    "        panier = []\n",
    "        for i in range(0, len(list_of_items_names)) :\n",
    "            if e[i] == 1 :\n",
    "                panier.append(list_of_items_names[i])\n",
    "        l.append(panier)\n",
    "    return l\n",
    "\n",
    "def get_transactions(list_of_transactions_names, list_of_transactions, itemset) :\n",
    "    output = \"\"\n",
    "    for i in range (0, len(list_of_transactions_names)) :\n",
    "        if itemset.issubset(frozenset(sorted(list_of_transactions[i]))) :\n",
    "            output += str(list_of_transactions_names[i])+\", \"\n",
    "    return output\n",
    "\n",
    "def to_resi_list(eplets_list) :\n",
    "    output = \"\"\n",
    "    eplets = re.findall(r'\\d+', eplets_list)\n",
    "    print(eplets)\n",
    "    for eplet in eplets :\n",
    "        output += str(eplet)+\"+\"\n",
    "    return output[:-1] # to delete the last '+'\n",
    "\n",
    "def closed_itemsets(df_itemsets) :\n",
    "\n",
    "    # get for each given support the list of itemsets\n",
    "    supports = {}\n",
    "    for i in range(0, len(freq_itemsets)) :\n",
    "        if freq_itemsets.support[i] in supports.keys() :\n",
    "            supports[freq_itemsets.support[i]].append(freq_itemsets.itemsets[i])\n",
    "        else :\n",
    "            supports[freq_itemsets.support[i]] = [freq_itemsets.itemsets[i]]\n",
    "\n",
    "    closed_itemsets = []        \n",
    "        \n",
    "    for support in supports.keys() :\n",
    "        sorted_list_of_itemsets = sorted(supports[support],key=len)\n",
    "        max_len = len(sorted_list_of_itemsets[-1])\n",
    "        for i in range(0, len(sorted_list_of_itemsets)) :\n",
    "            itemset = sorted_list_of_itemsets[i]\n",
    "            isClosed = True\n",
    "            if len(itemset) != max_len :\n",
    "                # check if subset of another set\n",
    "                for j in range (i+1, len(sorted_list_of_itemsets)) :\n",
    "                    if itemset.issubset(list(sorted_list_of_itemsets[j])) :\n",
    "                        isClosed = False\n",
    "                        break\n",
    "            if isClosed :\n",
    "                closed_itemsets.append((support, itemset))\n",
    "\n",
    "    closed_itemsets = pd.DataFrame(closed_itemsets, columns=['support', 'itemsets'])\n",
    "    return closed_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "database = widgets.Dropdown(\n",
    "    options = [\"ABC\", \"DRB\", \"DQB+DQA\", \"DPB+DPA\"],\n",
    "    value= None, \n",
    "    description='Database:', disabled=False )\n",
    "\n",
    "chain = widgets.RadioButtons(\n",
    "    options=['B', 'A'],\n",
    "    value=None,\n",
    "    description='Chaîne :',\n",
    "    disabled=False )\n",
    "\n",
    "direction = widgets.ToggleButtons(\n",
    "    options=['Eplets x Allèles', 'Allèles x Eplets'],\n",
    "    value=None,\n",
    "    disabled=False )\n",
    "\n",
    "eplets = widgets.ToggleButtons(\n",
    "    options=['Eplets confirmés', 'Tous les éplets'],\n",
    "    value=None,\n",
    "    disabled=False )\n",
    "\n",
    "alleles = widgets.ToggleButtons(\n",
    "    options=['Allèles Luminex', 'Toutes les allèles'],\n",
    "    value=None,\n",
    "    disabled=False )\n",
    "\n",
    "min_support = widgets.IntText(\n",
    "    value= 50,\n",
    "    description='Support minimum (en pourcentage) : ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "get_itemsets_button = widgets.Button(\n",
    "    description='Obtenir les itemsets fréquents',\n",
    "    disabled=False,\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "\n",
    "def database_eventhandler(*args):\n",
    "    output1.clear_output()\n",
    "    output2.clear_output()\n",
    "    \n",
    "    with output1 :\n",
    "        print(\"Téléchargement des données depuis HLA Epitope Registry ... \\n\")\n",
    "    (entries, list_of_luminex_alleles, list_of_all_alleles) = import_data_from_HLA_Epitope_Registry(database.value)\n",
    "    global matrixes \n",
    "    matrixes = create_matrices(entries, list_of_luminex_alleles, list_of_all_alleles)\n",
    "    #(df_all_eplets_vs_Luminex_alleles, df_all_eplets_vs_all_alleles, df_confirmed_eplets_vs_Luminex_alleles, df_confirmed_eplets_vs_all_alleles)     \n",
    "    \n",
    "    output1.clear_output()\n",
    "    with output1 :    \n",
    "        print( str(len(matrixes[0]))+\" éplets (dont \"+str(len(matrixes[2]))+ \\\n",
    "          \" confirmés) parmi \"+ str(len(matrixes[1].columns))+\" allèles (dont \"+ \\\n",
    "          str(len(matrixes[2].columns))+\" allèles Luminex) \\n\" )\n",
    "        \n",
    "    if database.value in [\"DQB+DQA\", \"DPB+DPA\"] :\n",
    "        (df_A, df_B) = split_A_B(matrixes[1])\n",
    "        (df_A_c, df_B_c) = split_A_B(matrixes[3])\n",
    "        (df_A_l, df_B_l) = split_A_B(matrixes[0])\n",
    "        with output1 :\n",
    "            print(\"Chaîne B : \"+ str(len(df_B)) +\" éplets (dont \"+ str(len(df_B_c))+\" confirmés) parmi \"+str(len(df_B.columns)) \\\n",
    "                  +\"allèles (dont \"+str(len(df_B_l.columns))+\" allèles Luminex) \\n Chaîne A : \"+ str(len(df_A)) \\\n",
    "                  +\" éplets (dont \"+ str(len(df_A_c))+\" confirmés) parmi \"+str(len(df_A.columns)) \\\n",
    "                  +\"allèles (dont \"+str(len(df_A_l.columns))+\" allèles Luminex)\")\n",
    "            \n",
    "            display(chain)\n",
    "            \n",
    "    else:\n",
    "        accordion()\n",
    "            \n",
    "def chain_eventhandler(*args) :\n",
    "    accordion()\n",
    "\n",
    "def accordion(*args) :\n",
    "    display(direction)\n",
    "    display(eplets)\n",
    "    display(alleles)\n",
    "    display(min_support)\n",
    "    display(get_itemsets_button)\n",
    "\n",
    "def on_change(change):\n",
    "    cls = change['new'].split(' ')\n",
    "    with output1 :\n",
    "        print(\"Here we are.\")\n",
    "        print(cls)\n",
    "    if len(cls) == 3: \n",
    "        place, txtrow, txtcol = cls\n",
    "        res = re.search(r'\\d+',txtrow).group(0)\n",
    "        \n",
    "        print(freq_itemsets.at[int(res), 'itemsets'])\n",
    "        \n",
    "        #print(\"chain B and resi \"+to_resi_list(str(freq_itemsets.at[int(res), 'itemsets'])))\n",
    "                    \n",
    "        #try:\n",
    "        #    to_color = \"chain B and resi \"+str(to_resi_list(str(freq_itemsets.at[int(res), 'itemsets'])))\n",
    "        #    print(to_color)\n",
    "        #    pymol.color('cyan', to_color)\n",
    "      \n",
    "        #except ValueError:\n",
    "        #    print(\"Error\")\n",
    "    \n",
    "def get_itemsets_eventhandler(*args) :\n",
    "    if direction.value != None and eplets.value != None and alleles.value != None and min_support.value != None :\n",
    "        df = pd.DataFrame()\n",
    "                \n",
    "        if eplets.value == 'Eplets confirmés' :\n",
    "            if alleles.value == 'Allèles Luminex' :\n",
    "                if database.value in [\"DQB+DQA\", \"DPB+DPA\"] :\n",
    "                    (A, B) = split_A_B(matrixes[2])\n",
    "                    if chain.value == 'A' :\n",
    "                        df = A\n",
    "                    else :\n",
    "                        df = B\n",
    "                else :\n",
    "                    df = matrixes[2]\n",
    "            else :\n",
    "                if database.value in [\"DQB+DQA\", \"DPB+DPA\"] :\n",
    "                    (A, B) = split_A_B(matrixes[3])\n",
    "                    if chain.value == 'A' :\n",
    "                        df = A\n",
    "                    else :\n",
    "                        df = B\n",
    "                else :\n",
    "                    df = matrixes[3]\n",
    "        else :\n",
    "            if alleles.value == 'Allèles Luminex' :\n",
    "                if database.value in [\"DQB+DQA\", \"DPB+DPA\"] :\n",
    "                    (A, B) = split_A_B(matrixes[0])\n",
    "                    if chain.value == 'A' :\n",
    "                        df = A\n",
    "                    else :\n",
    "                        df = B\n",
    "                else :\n",
    "                    df = matrixes[0]\n",
    "            else :\n",
    "                if database.value in [\"DQB+DQA\", \"DPB+DPA\"] :\n",
    "                    (A, B) = split_A_B(matrixes[1])\n",
    "                    if chain.value == 'A' :\n",
    "                        df = A\n",
    "                    else :\n",
    "                        df = B\n",
    "                else :\n",
    "                    df = matrixes[1]\n",
    "        if direction.value == 'Allèles x Eplets' :\n",
    "            df = df.transpose()\n",
    "        \n",
    "        global freq_itemsets\n",
    "        freq_itemsets = apriori(df, min_support=min_support.value/100, use_colnames=True)\n",
    "        freq_itemsets = closed_itemsets(freq_itemsets)\n",
    "        freq_itemsets['support'] = freq_itemsets['support'].apply(lambda x : round(x, 2))\n",
    "        freq_itemsets['count'] = freq_itemsets['support'].apply(lambda x : round(len(df)*x))\n",
    "\n",
    "        dataset = get_that_fucking_list(df)\n",
    "        freq_itemsets['transactions'] = freq_itemsets['itemsets'].apply(lambda x : get_transactions(df.index.values, dataset, x))\n",
    "\n",
    "                    \n",
    "        # javascript-part\n",
    "        script = \"\"\"\n",
    "        <script>\n",
    "        var input\n",
    "        var xpath = \"//input[contains(@placeholder,'undefined')]\";\n",
    "\n",
    "        function addHandlers() {\n",
    "            input = document.evaluate(xpath, document, null, \n",
    "                XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "            input.setAttribute(\"hidden\",\"\");\n",
    "\n",
    "            var table = document.querySelector(\"#T_table\");\n",
    "            var headcells = [].slice.call(table.getElementsByTagName(\"th\"));\n",
    "            var datacells = [].slice.call(table.getElementsByTagName(\"td\"));\n",
    "            var cells = headcells.concat(datacells);\n",
    "            for (var i=0; i < cells.length; i++) {\n",
    "               var createClickHandler = function(cell) {\n",
    "                 return function() { \n",
    "                    input = document.evaluate(xpath, document, null,\n",
    "                        XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                    input.value = cell.className; \n",
    "                    var event = new Event('change', { bubbles: true });\n",
    "                    input.dispatchEvent(event);\n",
    "              }}\n",
    "              cells[i].onclick = createClickHandler(cells[i]);\n",
    "            };\n",
    "        }\n",
    "\n",
    "        window.onload = setTimeout(addHandlers, 500);\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        display(HTML(script))\n",
    "\n",
    "        html = freq_itemsets[['itemsets', 'count', 'transactions']].sort_values('count', ascending=False) \\\n",
    "            .style.format({\"itemsets\": lambda x : list(x)}) \\\n",
    "            .hide_index() \\\n",
    "            .background_gradient(cmap='Blues', subset='count')\\\n",
    "            .set_uuid('table') \n",
    "\n",
    "        status = widgets.Text(placeholder='undefined',layout={'font-size':'6px'}) \n",
    "        status.observe(on_change,names=['value'])\n",
    "\n",
    "        table = widgets.Output()\n",
    "        #display(table)\n",
    "\n",
    "        with table:\n",
    "            display(html)         \n",
    "\n",
    "        a = widgets.VBox([status])\n",
    "        \n",
    "        display(table)\n",
    "        display(a)\n",
    "\n",
    "        #try: \n",
    "        #    pymol.start()   # Start PyMOL RPC server\n",
    "        #    pymol._add_methods()\n",
    "        #    pymol.fetch('4D8P') # Fetch PDB\n",
    "\n",
    "        #except ValueError:\n",
    "        #    print(\"Error\")\n",
    "            \n",
    "\n",
    "    else :\n",
    "        with output1 :\n",
    "            print(\"So. Here we are.\")          \n",
    "            \n",
    "            \n",
    "output1 = widgets.Output()\n",
    "output2 = widgets.Output() # tabs\n",
    "\n",
    "database.observe(database_eventhandler, 'value')\n",
    "chain.observe(chain_eventhandler, 'value')\n",
    "get_itemsets_button.on_click(get_itemsets_eventhandler)\n",
    "\n",
    "\n",
    "\n",
    "display(database)\n",
    "    \n",
    "display(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
